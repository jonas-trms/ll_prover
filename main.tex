\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[french]{babel}
\usepackage{fullpage}
\usepackage{amsmath,amsthm}
\usepackage{amssymb,cmll}
\usepackage{ebproof}
\usepackage{mathtools}
\usepackage{hyperref}
\usepackage{tikz}
\usetikzlibrary{trees}
\usepackage[ruled, french, frenchkw, onelanguage]{algorithm2e}

\theoremstyle{plain}
\newtheorem{theorem}{Théorème}
\theoremstyle{definition}
\newtheorem{definition}{Définition}
\theoremstyle{remark}
\newtheorem{example}{Exemple}

\renewcommand{\labelenumi}{(\alph{enumi})}
\renewcommand{\theenumi}{\labelenumi}

% dessins arbres : tikz
\tikzset{baseline=(current bounding box.center)}

%imported from click and collect
\newcommand*{\orth}{^\perp}
\newcommand*{\tensor}{\otimes}
\newcommand*{\one}{1}
\newcommand*{\plus}{\oplus}
\newcommand*{\zero}{0}
\newcommand*{\limp}{\multimap}

\newcommand*{\namedproofv}[2]{\hypo{#1}\infer[no rule]{1}{\vdash #2}}
\newcommand*{\hypv}[1]{\hypo{\vdash #1}}
\newcommand*{\exv}[2]{\infer{1}[\ensuremath{\mathit{ex}}]{\vdash #2}}
\newcommand*{\axv}[1]{\infer{0}[\ensuremath{\mathit{ax}}]{\vdash #1}}
\newcommand*{\cutv}[1]{\infer{2}[\ensuremath{\mathit{cut}}]{\vdash #1}}
\newcommand*{\onev}[1]{\infer{0}[\ensuremath{\one}]{\vdash #1}}
\newcommand*{\botv}[1]{\infer{1}[\ensuremath{\bot}]{\vdash #1}}
\newcommand*{\topv}[1]{\infer{0}[\ensuremath{\top}]{\vdash #1}}
\newcommand*{\tensorv}[1]{\infer{2}[\ensuremath{\tensor}]{\vdash #1}}
\newcommand*{\parrv}[1]{\infer{1}[\ensuremath{\parr}]{\vdash #1}}
\newcommand*{\permv}[2]{\infer{1}[\ensuremath{\textit{ex}_{#1}}]{\vdash #2}}
\newcommand*{\withv}[1]{\infer{2}[\ensuremath{\with}]{\vdash #1}}
\newcommand*{\pluslv}[1]{\infer{1}[\ensuremath{\plus_1}]{\vdash #1}}
\newcommand*{\plusrv}[1]{\infer{1}[\ensuremath{\plus_2}]{\vdash #1}}
\newcommand*{\ocv}[1]{\infer{1}[\ensuremath{\oc}]{\vdash #1}}
\newcommand*{\wkv}[1]{\infer{1}[\ensuremath{?\mathit{w}}]{\vdash #1}}
\newcommand*{\cov}[1]{\infer{1}[\ensuremath{?\mathit{c}}]{\vdash #1}}
\newcommand*{\dev}[1]{\infer{1}[\ensuremath{?\mathit{d}}]{\vdash #1}}
\newcommand*{\defv}[1]{\infer[dashed]{1}[\ensuremath{\mathit{def}}]{\vdash #1}}
\newcommand*{\permapp}[2]{#2 #1}
\newcommand*{\someperm}{\varsigma}
\newcommand*{\someadd}{\sigma}
\newcommand*{\someproof}{\pi}
\newcommand*{\sequent}{\Gamma}
\newcommand*{\sequentbis}{\Delta}
\newcommand*{\size}[1]{\mathopen{|}#1\mathclose{|}}


\newcommand*{\Left}{\textnormal{\texttt{L}}}
\newcommand*{\Right}{\textnormal{\texttt{R}}}
\newcommand*{\proofs}{\ensuremath{\mathcal{P}}}
\newcommand*{\sequents}{\ensuremath{\mathcal{S}}}
\newcommand*{\addresses}{\ensuremath{\mathcal{A}}}
\newcommand*{\trees}{\ensuremath{\mathcal{T}}}
\newcommand*{\treespartial}{\ensuremath{\mathcal{T'}}}
\newcommand*{\representationslarge}{\ensuremath{\trees \times \sequents}}
\newcommand*{\representations}{\ensuremath{\mathcal{R}}}
\newcommand*{\representationspartiallarge}{\ensuremath{\treespartial \times \sequents}}
\newcommand*{\representationspartial}{\ensuremath{\mathcal{R'}}}
\newcommand*{\encode}{\ensuremath{\varphi}}
\newcommand*{\decode}{\ensuremath{\gamma}}
\newcommand*{\height}{\ensuremath{h}}
\newcommand*{\relapprox}{\ensuremath{\triangleleft}}
\newcommand*{\relapproxlarge}{\ensuremath{\relapprox^*}}
\newcommand*{\unknown}{\mathcal{H}}

\newcommand*{\lowapprox}{\ensuremath{\Sigma_0}}
\newcommand*{\highapprox}{\ensuremath{\Sigma_1}}

\newcommand*{\todo}{{\normalfont \textbf{TODO}} }

\title{Rapport de stage}
\author{Jonas Torriero-Meskour}
%\date{June 2024}

\begin{document}

\maketitle

\section{Présentation du sujet et objectifs}
\todo{à détailler et compléter.}

Répondre à la même question que click and collect, d'une manière plus sobre : click and collect a une visée pédagogique, nous n'avons pas la même : droit au but, pour utilisateur expert.

On n'a fait que MLL. Expliquer la différence entre trouver une preuve, et construire une preuve particulière. Toutes les preuves ne se valent pas (éventuellement citer Curry-Howard).

Comme certains séquents ont plusieurs preuves : on ne peut pas afficher l'ensemble de toutes les preuves, ce qui serait trop compliqué. MLL NP-complet (pas trivial), LL indécidable (borne). On choisit donc de construire une preuve étape par étape, en guidant l'utilisateur.

\section{Représentation des preuves}
\subsection{Définitions préliminaires}
\subsubsection{Formules}
\begin{definition}[Formules]
On se donne un ensemble $\mathcal{X}$ infini d'atomes. Les formules en logique linéaire sont définies par la grammaire suivante:
\begin{equation*}
F := X \mid X\orth \mid F \parr F \mid F \tensor F
\end{equation*}
\end{definition}

\subsubsection{Preuves}
Les séquents sont des listes de formules. On note $\sequents$ l'ensemble des séquents. On définit alors l'ensemble \proofs{} des preuves en logique linéaire.
\begin{definition}[Preuves]
\proofs{} est défini par les règles d'induction suivantes:
\begin{equation*}
\begin{prooftree}
  \axv{X\orth, X}
\end{prooftree}
\qquad\qquad
\begin{prooftree}
  \hypv{\sequent}
  \permv{\someperm}{\permapp{\someperm}{\sequent}}
\end{prooftree}
\qquad\qquad
\begin{prooftree}
  \hypv{\sequent, A, B, \sequentbis}
  \parrv{\sequent, A \parr B, \sequentbis}
\end{prooftree}
\qquad\qquad
\begin{prooftree}
  \hypv{\sequent, A}
  \hypv{B, \sequentbis}
  \tensorv{\sequent, A \tensor B, \sequentbis}
\end{prooftree}
\end{equation*}
\end{definition}

\todo{Ajouter des exemples et comparer avec la logique classique, pour donner les intuitions et faire comprendre les objets.}

\subsection{Représentations}
On choisit de représenter une preuve $\someproof \in \mathcal{P}$ par un couple $(t, \sequent) \in \representationslarge$, où $t$ est un arbre encodant le squelette de la preuve, et $\sequent$ est le séquent prouvé.

\begin{definition}[Adresses]
On définit d'abord un ensemble d'adresses:
\begin{equation*}
\mathcal{A} = \mathbb{N} \times \{ \Left, \Right\}^{*}  
\end{equation*}
On considère que, dans un séquent $\sequent$, l'adresse $(n, \rho) \in \mathcal{A}$ représente la sous-formule d'adresse $\rho$ de la $n$\ieme{} formule de $\sequent$ (chaque formule pouvant être vue comme un arbre binaire).
\end{definition}

\begin{example}
Considérons le séquent suivant:
\begin{equation*}
X_1\orth, X_1 \tensor (X_2 \tensor X_3), X_3\orth, X_2\orth
\end{equation*}
$(1, \epsilon)$ représente la sous-formule $X_1\orth$, et $(2, \Right \cdot \Left)$ représente la sous-formule $X_2$. $(2, \Right)$ représente la sous-formule $X_2 \tensor X_3$.
\end{example}

\begin{definition}[Arbres]
\label{def_trees}
L'ensemble \trees{} des arbres est défini inductivement, par trois constructeurs:
\begin{itemize}
  \item un constructeur $0$-aire étiqueté par deux adresses: $F: \mathcal{A} \rightarrow \mathcal{A} \rightarrow \trees$
  \item un constructeur unaire étiqueté par une adresse: $U: \mathcal{A} \rightarrow \trees \rightarrow \trees$
  \item un constructeur binaire étiqueté par une adresse: $B: \mathcal{A} \rightarrow \trees \rightarrow \trees \rightarrow \trees$
\end{itemize}
\end{definition}

Chaque n\oe ud de l'arbre représente ainsi une règle de la preuve, par le biais de l'adresse qui l'étiquette, et qui renvoie à la sous-formule de $s$ sur laquelle la règle est appliquée. Le cas de l'axiome est particulier: un axiome est représenté par une feuille qui a deux adresses, renvoyant aux deux atomes duaux utilisés.

\begin{example}
Une preuve et sa représentation (la racine de la preuve est positionnée en bas, celle de l'arbre de la représentation est positionnée en haut):
\begin{equation*}
\begin{prooftree}
    \axv{{X_1}\orth, X_1}
    \axv{{X_2}\orth, X_2}
    \permv{(2, 1)}{X_2, {X_2}\orth}
    \tensorv{{X_1}\orth, X_1 \tensor X_2, {X_2}\orth}
    \parrv{{X_1}\orth \parr (X_1 \tensor X_2), {X_2}\orth}
\end{prooftree}
\quad\leadsto\quad
\begin{tikzpicture}%
    [level distance=1.5cm,
    level 2/.style={sibling distance=3.5cm}]
    \node {$U_{1 \epsilon}$}
    child {node {$B_{1 \Right}$}
        child {node {$F_{1 \Left, \; 1 \Right \cdot \Left}$}}
        child {node {$F_{1 \Right \cdot \Right, \; 2 \epsilon}$}}
    };
\end{tikzpicture}
\vdash {X_1}\orth \parr (X_1 \tensor X_2), {X_2}\orth
\end{equation*}
\end{example}

\subsection{Traduction}
Notre objectif est de définir une fonction d'encodage des preuves vers les représentations, puis de l'inverser.

\subsubsection{Encodage}

On identifie une fonction de $\addresses$ dans $\addresses$ et son extension de $\trees$ dans $\trees$, qui remplace chaque adresse de l'arbre par son image.

\begin{definition}[Fonction d'encodage]
  On définit d'abord une fonction $\encode' : \proofs \rightarrow \trees$, par induction sur $\proofs$:
    \begin{description}
    \item[Axiome:]
    $\encode' \left(
    \begin{prooftree}
        \axv{{X}\orth, X}
    \end{prooftree}
    \right) = F(1 \epsilon, \; 2 \epsilon)$

    \item[Échange:]
    $\encode' \left(
    \begin{prooftree}
      \namedproofv{\pi}{\sequent}
      \permv{\someperm}{\permapp{\someperm}{\sequent}}
    \end{prooftree}
    \right) = \someperm' \left( \encode ' \left(
           \begin{prooftree}
             \namedproofv{\pi}{\sequent}
           \end{prooftree} \right) \right)$
           
    où $\someperm'$ est la fonction qui applique $\someperm$ à l'arbre, puis trie les deux adresses de chaque feuille par ordre lexicographique.

    \item[Par:]
    $\encode' \left(
    \begin{prooftree}
      \namedproofv{\pi}{\sequent, A, B, \sequentbis}
      \parrv{\sequent, A \parr B, \sequentbis}
    \end{prooftree}
    \right) = \begin{tikzpicture}%
    [level distance=1.5cm,
    level 2/.style={sibling distance=3.5cm}]
    \node {$U_{n \epsilon}$}
        child {node {$\psi_\parr \left( \encode' \left(
           \begin{prooftree}
             \namedproofv{\pi}{\sequent, A, B, \sequentbis}
           \end{prooftree} \right) \right)$}
    };
    \end{tikzpicture}$
    
    où $n = \size{\sequent} + 1$
    
    $\psi_\parr : \addresses \rightarrow \addresses =
    \begin{cases*}
        (i, \someadd) \mapsto (i, \someadd) & si $i < n$ \\
        (n, \someadd) \mapsto (n, \Left \cdot \someadd)\\
        (n+1, \someadd) \mapsto (n, \Right \cdot \someadd)\\
        (i, \someadd) \mapsto (i-1, \someadd) & si $i \geq n+2$
    \end{cases*}$

    \item[Tenseur:]
    $\encode' \left(
    \begin{prooftree}
      \namedproofv{\pi_1}{\sequent, A}
      \namedproofv{\pi_2}{B, \sequentbis}
      \tensorv{\sequent, A \tensor B, \sequentbis}
    \end{prooftree}
    \right) = \begin{tikzpicture}%
    [level distance=1.5cm,
    level 1/.style={sibling distance=3.5cm}]
    \node {$B_{n \epsilon}$}
        child {node {$\psi_{\tensor\Left} \left( \encode' \left(
                \begin{prooftree}
                  \namedproofv{\pi_1}{\sequent, A}
                \end{prooftree}
              \right) \right)$}}
        child {node {$\psi_{\tensor\Right} \left( \encode' \left(
                \begin{prooftree}
                  \namedproofv{\pi_2}{B, \sequentbis}
                \end{prooftree}
              \right) \right)$}
    };
    \end{tikzpicture}$
    
    où $n = \size{\sequent} + 1$
    
    $\psi_{\tensor\Left} : \addresses \rightarrow \addresses =
    \begin{cases*}
        (n, \someadd) \mapsto (n, \Left \cdot \someadd)\\
        (i, \someadd) \mapsto (i, \someadd) & si $i \neq n$
    \end{cases*}$
    
    $\psi_{\tensor\Right} : \addresses \rightarrow \addresses =
    \begin{cases*}
        (1, \someadd) \mapsto (n, \Right \cdot \someadd)\\
        (i, \someadd) \mapsto (i + n - 1, \someadd) & si $i \geq 2$
    \end{cases*}$
  \end{description}

    On préserve l'ordre lexicographique sur les feuilles, car on souhaite moralement étiqueter celles-ci par des paires d'adresses, qu'on implémente en pratique par des couples ordonnés. En effet, la règle d'axiome étant unique, la donnée de la paire d'atomes utilisés suffit à retrouver la preuve.

    On définit ensuite la fonction d'encodage $\encode : \proofs \rightarrow \representationslarge$:
    \begin{equation*}
    \forall \someproof \in \proofs, \encode \left( \someproof \right) = \left( \encode' \left( \someproof \right), \; \sequent \right), \; \text{noté $\encode' \left( \someproof \right) \vdash \sequent$, où $\sequent$ est le séquent prouvé par $\someproof$.}
    \end{equation*}
\end{definition}

On cherche ensuite à restreindre l'ensemble des représentations, pour ne conserver que celles qui sont effectivement l'encodage d'une preuve.

\begin{definition}[Représentations correctes]
    \label{def_rep}
    On définit l'ensemble \representations{} des représentations correctes comme les éléments $(t, \sequent)$ de $\representationslarge$ vérifiant les trois conditions suivantes:
    
    \begin{enumerate}
    \item\label{cadd} \textbf{Bon adressage:} Chaque adresse apparaissant dans une feuille ou un n\oe ud de $t$ est celle d'un atome ou d'un opérateur de $\sequent$. De plus, l'arité d'un n\oe ud est égale à celle de la règle de l'opérateur qu'il adresse, et chaque feuille adresse deux atomes duaux. Enfin, les deux adresses d'une feuille sont triées (par ordre lexicographique, en considérant que $\Left < \Right)$.
    \item\label{clin} \textbf{Linéarité:} Chaque sous-formule de $\sequent$ apparaît exactement une fois dans les adresses de $t$.
    \item\label{cdes} \textbf{Descendance:} Une adresse de $t$ de la forme $(n, \someadd \cdot \alpha)$ descend nécessairement d'un n\oe ud adressant $(n, \someadd)$ (possiblement à distance plus grande que $1$). De plus, pour tout n\oe ud de la forme $B((n, \someadd), \; g, \; d)$, $(n, \someadd \cdot \Right)$ ne peut apparaître dans $g$, et $(n, \someadd \cdot \Left)$ ne peut apparaître dans $d$.
    \end{enumerate}
\end{definition}

\begin{theorem}[Image de l'encodage]
    \begin{equation*}
    \forall \someproof \in \proofs, \encode \left( \someproof \right) \in \representations
    \end{equation*}

    Autrement dit, l'encodage d'une preuve est une représentation correcte.
\end{theorem}

\begin{proof}
    Par induction sur $\someproof \in \proofs$:
    \begin{description}
    \item[Axiome:] $\someproof =
    \begin{prooftree}
        \axv{X\orth, X}
    \end{prooftree}$,
    et donc $\encode \left( \someproof \right) = F(1 \epsilon, 2 \epsilon) \vdash X\orth, X$

    On vérifie aisément les conditions \ref{cadd}, \ref{clin} et \ref{cdes} de la définition \ref{def_rep}, d'où $\encode \left( \someproof \right) \in \representations$.

    \item[Échange:] $\someproof =
    \begin{prooftree}
        \namedproofv{\pi_1}{\sequent}
        \permv{\someperm}{\permapp{\someperm}{\sequent}}
    \end{prooftree}$.
    
    Par hypothèse d'induction, $\encode \left( \pi_1 \right) = \encode ' \left( \pi_1 \right) \vdash \sequent$ vérifie \ref{cadd}, \ref{clin} et \ref{cdes}. Les conditions \ref{clin} et \ref{cdes} sont stables par ré-adressage par $\someperm$, étant donné que les conditions portent sur les adresses de l'arbre et du séquent, et qu'on ré-adresse les deux identiquement. La condition \ref{cadd} est également préservée, car on s'assure de trier les adresses des feuilles après avoir ré-adressé par $\someperm$.

    On en déduit que $\encode \left( \someproof \right) = \someperm' \left( \encode ' \left( \pi_1 \right) \right) \vdash \permapp{\someperm}{\sequent}$ vérifie \ref{cadd}, \ref{clin} et \ref{cdes}, d'où $\encode \left( \someproof \right) \in \representations$.

    \item[Par:] $\someproof =
    \begin{prooftree}
      \namedproofv{\pi_1}{\sequent, A, B, \sequentbis}
      \parrv{\sequent, A \parr B, \sequentbis}
    \end{prooftree}$

    Par hypothèse d'induction, $\encode \left( \pi_1 \right) = \encode ' \left( \pi_1 \right) \vdash \sequent, A, B, \sequentbis$ vérifie \ref{cadd}, \ref{clin} et \ref{cdes}.
    
    On a, de plus:
    \begin{equation*}
    \encode ( \someproof ) = \begin{tikzpicture}%
    [level distance=1.5cm,
    level 2/.style={sibling distance=3.5cm}]
    \node {$U_{n \epsilon}$}
        child {node {$\psi_\parr \left( \encode' \left( \pi_1 \right) \right)$}
    };
    \end{tikzpicture} \vdash \sequent, A \parr B, \sequentbis
    \end{equation*}

    Vérifions les trois conditions:
    \begin{enumerate}
        \item\label{pcadd} L'adresse $n \epsilon$, adressant un par, étiquette la racine d'arité 1, celle-ci est donc correcte.
        
        Par ailleurs, \ref{cadd} est vérifié pour $\encode ' \left( \pi_1 \right) \vdash \sequent, A, B, \sequentbis$, d'où, grâce au ré-adressage effectué par $\psi_\parr$, les adresses de $\psi_\parr \left( \encode' \left( \pi_1 \right) \right)$ sont correctes. En effet, les sous-adresses de $A$ deviennent des sous-adresses gauches de $A \tensor B$, celles de $B$ des sous-adresses droites de $A \tensor B$, et les adresses de $\sequentbis$ dont décalées de $1$, étant donné que $A$ et $B$ ont été fusionnées, diminuant la longueur du séquent de $1$.
        
        Toutes les adresses sont donc correctes, et le bon adressage est préservé.
        
        \item D'une part, \ref{clin} étant vérifiée pour $\encode ' \left( \pi_1 \right) \vdash \sequent, A, B, \sequentbis$, et le ré-adressage par $\psi_\parr$ étant injectif, les adresses de $\psi_\parr \left( \encode' \left( \pi_1 \right) \right)$ sont distinctes.
        
        D'autre part, chaque sous-formule de $\sequent, A, B, \sequentbis$ est étiquetée par au moins un noeud de $\encode ' \left( \pi_1 \right)$, d'après \ref{clin}. Le ré-adressage par $\psi_\parr$ étant correct (voir preuve de \ref{pcadd}), chaque sous-formule de $\sequent, A \parr B, \sequentbis$, à l'exception de $A \parr B$, est étiquetée par au moins un noeud de $\psi_\parr \left( \encode' \left( \pi_1 \right) \right)$.
        
        Chaque sous-formule de $\sequent, A, B, \sequentbis$ est donc étiquetée par un unique noeud de $\encode ' \left( \pi_1 \right)$.
        
        $A \parr B$ est quant à lui étiqueté par la racine, et c'est le seul endroit où son adresse apparaît, car, par construction de $\psi_\parr$, aucun noeud de $\psi_\parr \left( \encode' \left( \pi_1 \right) \right)$ ne peut être étiqueté par $n \epsilon$.

        Finalement, chaque sous-adresse de $\sequent, A \parr B, \sequentbis$ apparaît une et une seule fois dans l'arbre, la linéarité en est donc préservée.
        
        \item La condition \ref{cdes} est vérifiée pour $\encode ' \left( \pi_1 \right)$. Intéressons-nous au nouvel arbre.
        
        La racine est étiquetée par $n \epsilon$, ce qui convient.

        Par ailleurs, le ré-adressage par $\psi_\parr$ préserve le fait d'être une sous-adresse, d'où \ref{cdes} est vérifiée pour $\psi_\parr \left( \encode' \left( \pi_1 \right) \right)$.
\todo{détailler le cas de $A$ et de $B$}

        Ainsi, \ref{cdes} est vérifiée pour le nouvel arbre.
    \end{enumerate} 

    On a bien \ref{cadd}, \ref{clin} et \ref{cdes}, d'où $\encode \left( \someproof \right) \in \representations$.

     \item[Tenseur:] $\someproof =
    \begin{prooftree}
      \namedproofv{\pi_1}{\sequent, A}
      \namedproofv{\pi_2}{B, \sequentbis}
      \tensorv{\sequent, A \tensor B, \sequentbis}
    \end{prooftree}$

    Par hypothèses d'induction, $\encode \left( \pi_1 \right) = \encode ' \left( \pi_1 \right) \vdash \sequent, A$ et $\encode \left( \pi_2 \right) = \encode ' \left( \pi_2 \right) \vdash B, \sequentbis$ vérifient \ref{cadd}, \ref{clin} et \ref{cdes}.
    
    De plus:
    \begin{equation*}
    \encode ( \someproof ) = \begin{tikzpicture}%
    [level distance=1.5cm,
    level 1/.style={sibling distance=3.5cm}]
    \node {$B_{n \epsilon}$}
        child {node {$\psi_{\tensor\Left} \left( \encode' \left( \pi_1 \right) \right)$}}
        child {node {$\psi_{\tensor\Right} \left( \encode' \left( \pi_2 \right) \right)$}
    };
    \end{tikzpicture} \vdash \sequent, A \tensor B, \sequentbis
    \end{equation*}

    Vérifions les trois conditions:
    \begin{enumerate}
        \item L'argument est similaire au cas du par: les adresses de $A$ et $B$ deviennent des sous-adresses gauches et droites de $A \tensor B$, et un décalage est effectué sur les adresses de $\sequentbis$, à cause de la fusion des séquents.

        \item À nouveau, l'argument pour $\psi_{\tensor\Left} \left( \encode' \left( \pi_1 \right) \right)$ et $\psi_{\tensor\Right} \left( \encode' \left( \pi_2 \right) \right)$ est similaire au cas du par: le ré-adressage est correct, et on se sert des hypothèses d'induction.
        
        Le cas de la racine se traite également comme pour le par.

        \item De la même manière que pour le par, en utilisant les hypothèses d'induction et par construction des fonctions de ré-adressage, la descendance est préservée au sein de $\psi_{\tensor\Left} \left( \encode' \left( \pi_1 \right) \right)$ et $\psi_{\tensor\Right} \left( \encode' \left( \pi_2 \right) \right)$.

        Par ailleurs, la racine est étiquetée par $n \epsilon$, ce qui convient. Il s'agit de plus d'un noeud de la forme $B(n \epsilon)$, et, par construction de $\psi_{\tensor\Left}$, aucun noeud de $\psi_{\tensor\Left} \left( \encode' \left( \pi_1 \right) \right)$ ne peut être étiqueté par $n \Right$. Idem pour $\psi_{\tensor\Right} \left( \encode' \left( \pi_2 \right) \right)$ qui ne peut contenir $n \Left$.

        La racine vérifie ainsi toutes les conditions, la descendance est donc préservée.
    \end{enumerate}

    On en déduit $\encode \left( \someproof \right) \in \representations$.
    \end{description}

    Ainsi, $\forall \someproof \in \proofs, \encode \left( \someproof \right) \in \representations$.
\end{proof}

\subsubsection{Décodage}

\begin{theorem}[Inversion des représentations correctes]
\begin{equation*}
\forall (t,s) \in \representations, \; \exists \someproof \in \proofs, \; \encode \left( \someproof \right) = (t, s)
\end{equation*}
Autrement dit, toute représentation correcte est bien l'encodage d'une preuve.
\end{theorem}

\begin{proof}
Par récurrence sur la hauteur $\height$ de $t \in \trees$. On regarde le n\oe ud présent à la racine:
\begin{description}
    \item[$F$:]
    Si $(t, s) = F(n\rho, n'\rho') \vdash \sequent \in \representations$.

    D'après la condition (c) de descendance, on a nécessairement $\rho = \rho' = \epsilon$.

    D'après la condition (b) de linéarité, $n \neq n'$, $\size{\sequent} = 2$ et $\{n, n'\} = \{1, 2\}$.

    D'après la condition (a) de bon adressage, $n = 1$, $n' = 2$, et $\sequent = X\orth, X$ ou $\sequent = X, X\orth$, avec $X$ un atome.

    Dans le premier cas,
    $\someproof = \begin{prooftree}
            \axv{X\orth, X}
        \end{prooftree}$ convient donc, puisque $\encode \left( \someproof \right) = F(1 \epsilon, 2 \epsilon) \vdash X\orth, X = (t,s)$.

    Dans le second cas,
    $\someproof = \begin{prooftree}
            \axv{X\orth, X}
            \permv{(2, 1)}{X, X\orth}
        \end{prooftree}$ convient donc, puisque $\encode \left( \someproof \right) = F(1 \epsilon, 2 \epsilon) \vdash X, X\orth = (t,s)$.

     \todo{compléter la preuve}
     
    \item[$U$:] 

    \item[$B$:] 
  \end{description}
\end{proof}

\todo{Parler du noyau de la fonction d'encodage, soit avec une propriété à exprimer, soit en donnant des exemples de formules "distinctes" mais identifiables ayant la même image, pour montrer que l'information qu'on perd n'est que celle liée aux permutations.}

\todo{Faire le lien avec le code}

\section{Manipulation interactive des représentations}
L'utilisateur ne travaillera pas directement sur des preuves partielles, mais sur des représentations partielles de preuves. On généralise donc la définition \ref{def_trees}.

\begin{definition}[Arbres partiels]
    L'ensemble \treespartial{} des arbres partiels est défini inductivement, par quatre constructeurs:
    \begin{itemize}
      \item un constructeur $0$-aire, le "trou": $\unknown: \treespartial$
      \item un constructeur $0$-aire étiqueté par deux adresses: $F: \mathcal{A} \rightarrow \mathcal{A} \rightarrow \treespartial$
      \item un constructeur unaire étiqueté par une adresse: $U: \mathcal{A} \rightarrow \treespartial \rightarrow \treespartial$
      \item un constructeur binaire étiqueté par une adresse: $B: \mathcal{A} \rightarrow \treespartial \rightarrow \treespartial \rightarrow \treespartial$
    \end{itemize}
\end{definition}

Les arbres complets \trees{} sont en particulier des arbres partiels appartenant à \treespartial{}. On interprète un trou dans un arbre partiel comme étant une partie de cet arbre qu'on ne connaît pas encore. Au cours de l'interaction avec l'utilisateur, on éliminera peu à peu les trous, en gagnant de l'information au fur et à mesure. On définit une relation d'approximation sur \treespartial{}, pour formaliser cette notion.

\begin{definition}[Relation d'approximation]
    Soient $t', t \in \treespartial$. $t'$ est une approximation immédiate de $t$, notée $t' \relapprox t$, si $t$ s'obtient en remplaçant un trou $\unknown$ quelconque de $t'$ par un constructeur de la forme $F(a_1, a_2)$, $U(a_1, \unknown)$ ou $B(a_1, \unknown, \unknown)$, avec $a_1, a_2 \in \addresses$.

    On étend cette relation à sa clôture réflexive et transitive, notée $\relapproxlarge$.
\end{definition}
\todo{Ajouter des exemples}

Lors de l'interaction avec l'utilisateur, on souhaite s'intéresser uniquement à des approximations de représentations correctes, qu'on veut donc caractériser. On étend pour ce faire la définition \ref{def_rep}.

\begin{definition}[Représentations partielles correctes]
    \label{def_rep_partial}
    On définit l'ensemble \representationspartial{} des représentations correctes comme les éléments $(t, \sequent)$ de $\representationspartiallarge$ vérifiant les trois conditions suivantes:
    
    \begin{enumerate}
    \item\label{caddpartial} \textbf{Bon adressage:} Même condition que \ref{cadd} de la définition \ref{def_rep}, en considérant que les feuilles $\unknown$ ne portent aucune adresse.
    \item\label{clinpartial} \textbf{Sous-linéarité:} Chaque sous-formule de $\sequent$ apparaît au plus une fois dans les adresses de $t$.
    \item\label{cdespartial} \textbf{Descendance:} Même condition que \ref{cdes} de la définition \ref{def_rep}.
    \end{enumerate}
\end{definition}

\begin{theorem}
    Soit $(t, s) \in \representationslarge$ tel que $(t, s) \in \representations$, et soit $t' \in \treespartial$ tel que $t' \relapproxlarge t$. Alors $(t', s) \in \representationspartial$.
    
    Autrement dit, une approximation d'une représentation correcte est une représentation partielle correcte.
\end{theorem}

\begin{proof}
    Les trois conditions de la définition \ref{def_rep} sont vérifiées pour $(t, s)$, et en particulier les conditions de la définition \ref{def_rep_partial}, qui en sont une version plus faible. 
    
    $t'$ s'obtient en remplaçant un nombre fini de noeuds de $t$ par des feuilles $?$, en partant des feuilles et en percolant vers le haut. Cette opération préserve les trois conditions de la définition \ref{def_rep_partial}:

    \begin{enumerate}
        \item On a seulement retiré des adresses, les adresses qui restent dans $t'$ sont donc correctes car elles l'étaient déjà dans $t$.

        \item De même, on n'a fait que retirer des adresses, et on doit vérifier que les adresses qui restent dans $t'$ sont distinctes. C'est vrai, car les adresses de $t$ étaient déjà distinctes.

        \item On retire les adresses en percolant vers le haut depuis les feuilles. On ne se trouve donc jamais dans le cas où l'on retire une adresse ayant des descendants, ce qui préserve la condition de descendance.
    \end{enumerate}
\end{proof}

La construction d'une preuve se fera de la manière suivante : étant donné un séquent $\sequent$, l'utilisateur partira de la représentation partielle correcte minimale $(?, \; \sequent)$, et construira, étape par étape, une suite d'approximations immédiates, aboutissant, si le séquent est prouvable, à une représentation totale correcte.

L'objectif de notre assistant de preuve est de guider l'utilisateur dans cette démarche, en lui indiquant de la manière la plus fine possible les adresses qu'il peut choisir, à chaque étape, pour construire la suite d'approximations, tout en préservant la correction.

On définit pour cela deux ensembles approximant ces adresses.

\begin{definition}[Approximations basse et haute d'adresses]
    Soit $(t', s) \in \representationspartial$, tel que $t' \notin \trees$. $t'$ a donc un nombre $n$ non nul de feuilles $\unknown$. Soit $1 \leq i \leq n$, et considérons le $i$\ieme{} trou $\unknown$ en partant de la gauche.

    On définit alors :
    \begin{align*}
        & \begin{multlined}
            \highapprox \left( (t', s), \; i \right) = \{ a \in \addresses, \; \exists t \in \treespartial, \; t' \relapprox t \; \text{en ayant remplacé le $i$\ieme{} trou}, \; (t, s) \in \representationspartial, \; \\
            \text{$a$ étiquette le nouveau noeud de $t'$} \}
        \end{multlined}\\
        & \begin{multlined}
            \lowapprox \left( (t', s), \; i \right) = \{ a \in \highapprox \left( (t', s), \; i \right), \; \forall t \in \trees, t' \relapproxlarge t, \; (t, s) \in \representations, \; \\
            \text{$a$ apparaît dans la branche de $t$ remplaçant le $i$\ieme{} trou de $t'$}
            \}
        \end{multlined}
    \end{align*} 
    
\end{definition}

On donne un algorithme calculant ces deux ensembles, pour une représentation partielle correcte et un trou donnés.

\begin{algorithm}[H]
\caption{Calcul des approximations basse et haute d'adresses}\label{algo_approx}
\KwData{$(t', s) \in \representationspartial$, tel que $t' \notin \trees$. $0 \leq i \leq n$, où $n$ est le nombre de trous de $t'$.}
\KwResult{$\lowapprox \left( (t', s), \; i \right)$ et $\highapprox \left( (t', s), \; i \right)$.}
$\highapprox \gets \{ (j, \epsilon), \; 0 \leq j \leq |s| \}$\;
$\lowapprox \gets \highapprox$\;
$t'_{curr} \gets t'$\;

\While{$t'_{curr} \neq \unknown$}{
    \Switch{la forme de $t'_{curr}$}{
        \Case{$t'_{curr} = U((m, \someadd), t_1)$}{
            $\highapprox \gets {\highapprox}_{\setminus \{ (m, \someadd) \}} \cup \left\{ (m, \someadd \cdot \Left), (m, \someadd \cdot \Right)\right\}$\;
            $\lowapprox \gets {\lowapprox}_{\setminus \{ (m, \someadd) \}} \cup \left\{ (m, \someadd \cdot \Left), (m, \someadd \cdot \Right)\right\}$\;
            $t'_{curr} \gets t_1$\;
        }

        \Case{$t'_{curr} = B((m, \someadd), t_1, t_2)$ et le $i\ieme$ trou est dans $t_1$}{
            $\mathcal{M} \gets \left\{\text{$a$, où $a$ est une adresse minimale apparaissant dans $t_2$}\right\}$\;
            $\highapprox \gets {\highapprox}_{\setminus \mathcal{M} \cup \{ (m, \someadd) \}} \cup \left\{ (m, \someadd \cdot \Left) \right\}$\;
            \eIf{$t_2 \in \trees$}{
                $\lowapprox \gets \highapprox \cap \left( \lowapprox \cup \left\{ (m, \someadd \cdot \Left) \right\} \right)$
            }{
                $\lowapprox \gets \left\{ (m, \someadd \cdot \Left) \right\}$
            }
            $t'_{curr} \gets t_1$\;
        }

        \Case{$t'_{curr} = B((m, \someadd), t_1, t_2)$ et le $i\ieme$ trou est dans $t_2$}{
            Symétrique du cas précédent.
        }
    }
}
\KwRet{$\lowapprox, \highapprox$}\;
\end{algorithm}

\begin{theorem}
    L'algorithme \ref{algo_approx} termine et est correct.
\end{theorem}

\todo{Faire le lien avec le code}

\todo{Montrer que la spécification est une approximation des ensembles idéaux}

\todo{Prouver la correction et la complétude à partir d'une suite exacte d'approx partielles}

\section{Complétion automatique}

\end{document}
